<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Wixb blog</title>
    <link>http://wixb50.gitcafe.io/categories/docker/</link>
    <description>Recent content in Docker on Wixb blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>wixb50@gmail.com (Wixb)</managingEditor>
    <webMaster>wixb50@gmail.com (Wixb)</webMaster>
    <copyright>(c) 2015 wixb.All rights reserved.</copyright>
    <lastBuildDate>Wed, 30 Dec 2015 19:10:38 +0800</lastBuildDate>
    <atom:link href="http://wixb50.gitcafe.io/categories/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Docker集群系列之－ESXi5.5上搭建基于CoreOS的kubernetes集群</title>
      <link>http://wixb50.gitcafe.io/2015/12/30/docker%E9%9B%86%E7%BE%A4%E7%B3%BB%E5%88%97%E4%B9%8Besxi5.5%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8Ecoreos%E7%9A%84kubernetes%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Wed, 30 Dec 2015 19:10:38 +0800</pubDate>
      <author>wixb50@gmail.com (Wixb)</author>
      <guid>http://wixb50.gitcafe.io/2015/12/30/docker%E9%9B%86%E7%BE%A4%E7%B3%BB%E5%88%97%E4%B9%8Besxi5.5%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8Ecoreos%E7%9A%84kubernetes%E9%9B%86%E7%BE%A4/</guid>
      <description>

&lt;h1 id=&#34;目录&#34;&gt;目录&lt;/h1&gt;

&lt;!-- MarkdownTOC --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#coreos-on-vmware&#34;&gt;CoreOS on VMware&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cloud-config-for-master-node&#34;&gt;Cloud-Config for master node&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cloud-config-for-minion-node&#34;&gt;Cloud-Config for minion node&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#start-the-cluster&#34;&gt;Start the cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#check&#34;&gt;Check&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#enjoy&#34;&gt;Enjoy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- /MarkdownTOC --&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Create a Kubernetes Cluster on VMware ESXi with CoreOS.&lt;/p&gt;

&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;VMware ESXi

&lt;ul&gt;
&lt;li&gt;(optional) a DRS cluster with VCenter for high-availability host.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;DHCP server&lt;/li&gt;
&lt;li&gt;A VMware datastore&lt;/li&gt;
&lt;li&gt;vSphere&lt;/li&gt;
&lt;li&gt;Attention: This requires at least CoreOS version 695.0.0, which includes etcd2.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;coreos-on-vmware&#34;&gt;CoreOS on VMware&lt;/h1&gt;

&lt;p&gt;Based on official documentation : &lt;a href=&#34;https://coreos.com/os/docs/latest/booting-on-vmware.html&#34;&gt;https://coreos.com/os/docs/latest/booting-on-vmware.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Download the OVA, on your local computer :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -LO http://alpha.release.core-os.net/amd64-usr/current/coreos_production_vmware_ova.ova
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Import ova on VMware via the vSphere Client :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;in the menu, click &amp;quot;File &amp;gt; Deploy OVF Template...&amp;quot;
in the wizard, specify the location of the OVA downloaded earlier
name your VM
confirm the settings then click &amp;quot;Finish&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a template via vSphere Client :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;right click on the VM and Template &amp;gt; Convert into template
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can create -at least- 2 servers based on this template, do this task but don&amp;rsquo;t start it yet.&lt;/p&gt;

&lt;h1 id=&#34;cloud-config-for-master-node&#34;&gt;Cloud-Config for master node&lt;/h1&gt;

&lt;p&gt;On the VMware datastore, create a directory and initialize config, example :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p &amp;lt;path to datastore&amp;gt;/cloud-config/master/openstack/latest/ 
cd &amp;lt;path to datastore&amp;gt;/cloud-config/master/openstack/latest/
wget https://raw.githubusercontent.com/kubernetes/kubernetes/master/docs/getting-started-guides/coreos/cloud-configs/master.yaml &amp;amp;&amp;amp; mv master.yaml user_data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don&amp;rsquo;t forget to add your ssh_key :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vim user_data
users:
  - name: &amp;quot;core&amp;quot;
    groups:
      - &amp;quot;sudo&amp;quot;
      - &amp;quot;docker&amp;quot;
    ssh-authorized-keys:   
      - ssh-rsa AAAA...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because the master need a static ip address,so you need to add the ip config to &lt;code&gt;user_data&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vim user_data
write-files:
  [...]
  - path: /etc/systemd/network/static.network
    permissions: 0644
    content: |
      [Match]
      Name=ens192  # The network card

      [Network]
      Address=192.1.1.150/24
      Gateway=192.1.1.1
      DNS=10.11.248.114
      DNS=8.8.4.4
  [...]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you can&amp;rsquo;t get the files on VM,you need download files first,and deploy to your &lt;code&gt;File Server&lt;/code&gt;first.And change the url in the &lt;code&gt;user_data&lt;/code&gt; to your own file position.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Replace `https://github.com/kelseyhightower/setup-network-environment/releases/download/v1.0.0/setup-network-environment` To `&amp;lt;your file url&amp;gt;/setup-network-environment`
Replace `https://storage.googleapis.com/kubernetes-release/release/v1.1.2/bin/linux/amd64/kube-apiserver` To `&amp;lt;your file url&amp;gt;/kube-apiserver`
Replace `https://storage.googleapis.com/kubernetes-release/release/v1.1.2/bin/linux/amd64/kube-controller-manager` To `&amp;lt;your file url&amp;gt;/kube-controller-manager`
Replace `https://storage.googleapis.com/kubernetes-release/release/v1.1.2/bin/linux/amd64/kube-scheduler` To `&amp;lt;your file url&amp;gt;/kube-scheduler`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finaly, replace all &amp;laquo;$private_ipv4&amp;raquo; pattern with the ip of master node. The only way to perform this is to fix a DHCP lease with the MAC address of your master server. This MAC address can be get on vsphere : right click on VM, network adapter. Here, 10.0.0.1 is the master fixed ip address.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed -i &#39;s|$private_ipv4|10.0.0.1|g&#39; user_data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the limitation with coreOS and VMware : &lt;a href=&#34;https://coreos.com/os/docs/latest/booting-on-vmware.html#cloud-config&#34;&gt;https://coreos.com/os/docs/latest/booting-on-vmware.html#cloud-config&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Last step : create an iso :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd &amp;lt;path to datastore&amp;gt;/cloud-config/
mkisofs -R -V config-2 -o config-master.iso master/
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;cloud-config-for-minion-node&#34;&gt;Cloud-Config for minion node&lt;/h1&gt;

&lt;p&gt;On the VMware datastore, create a directory and initialize config, example :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p &amp;lt;path to datastore&amp;gt;/cloud-config/minion/openstack/latest/
cd &amp;lt;path to datastore&amp;gt;/cloud-config/minion/openstack/latest/
wget https://raw.githubusercontent.com/kubernetes/kubernetes/master/docs/getting-started-guides/coreos/cloud-configs/node.yaml &amp;amp;&amp;amp; mv node.yaml user_data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don&amp;rsquo;t forget to add your ssh_key :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vim user_data
users:
  - name: &amp;quot;core&amp;quot;
    groups:
      - &amp;quot;sudo&amp;quot;
      - &amp;quot;docker&amp;quot;
    ssh-authorized-keys:   
      - ssh-rsa AAAA...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you can&amp;rsquo;t get the files on VM,you need download files first,and deploy to your &lt;code&gt;File Server&lt;/code&gt;first.And change the url in the &lt;code&gt;user_data&lt;/code&gt; to your own file position.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Replace `https://github.com/kelseyhightower/setup-network-environment/releases/download/v1.0.0/setup-network-environment` To `&amp;lt;your file url&amp;gt;/setup-network-environment`
Replace `https://storage.googleapis.com/kubernetes-release/release/v1.1.2/bin/linux/amd64/kube-proxy` To `&amp;lt;your file url&amp;gt;/kube-proxy`
Replace `https://storage.googleapis.com/kubernetes-release/release/v1.1.2/bin/linux/amd64/kubelet` To `&amp;lt;your file url&amp;gt;/kubelet`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finaly, replace all &amp;laquo;&lt;master-private-ip&gt;&amp;raquo; pattern with the ip of master node. (here 10.0.0.1)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed -i &#39;s|&amp;lt;master-private-ip&amp;gt;|10.0.0.1|g&#39; user_data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Last step : create an iso :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd &amp;lt;path to datastore&amp;gt;/cloud-config/
mkisofs -R -V config-2 -o config-minion.iso minion/
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;start-the-cluster&#34;&gt;Start the cluster&lt;/h1&gt;

&lt;p&gt;On firt VM, mount the config-master.iso with VM properties (CD/DVD reader and &amp;laquo;Datastore ISO file&amp;raquo;), browse to &amp;laquo;&lt;path to datastore&gt;/cloud-config/&amp;laquo;. Don&amp;rsquo;t foget to set &amp;laquo;Connect on Start up&amp;raquo;.&lt;/p&gt;

&lt;p&gt;On second, and all other futher nodes  mount the config-minion.iso.&lt;/p&gt;

&lt;p&gt;Start your servers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt;&lt;br /&gt;
In order to build the &lt;code&gt;flanneld&lt;/code&gt;,the VMs need to pull the images called &lt;code&gt;quay.io/coreos/flannel&lt;/code&gt;.And if the VMs can&amp;rsquo;t download it,you should get it first,then use the command to load the image.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker load &amp;lt; flanneld-file.tar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ensure all the &lt;code&gt;service&lt;/code&gt; are running.&lt;br /&gt;
&lt;strong&gt;Master:&lt;/strong&gt;&lt;code&gt;docker&lt;/code&gt;、&lt;code&gt;etcd2&lt;/code&gt;、&lt;code&gt;fleet&lt;/code&gt;、&lt;code&gt;flanneld&lt;/code&gt;、&lt;code&gt;setup-network-environment&lt;/code&gt;、&lt;code&gt;kube-apiserver&lt;/code&gt;、&lt;code&gt;kube-controller-manager&lt;/code&gt;、&lt;code&gt;kube-scheduler&lt;/code&gt;.&lt;br /&gt;
&lt;strong&gt;Node:&lt;/strong&gt;&lt;code&gt;docker&lt;/code&gt;、&lt;code&gt;etcd2&lt;/code&gt;、&lt;code&gt;fleet&lt;/code&gt;、&lt;code&gt;flanneld&lt;/code&gt;、&lt;code&gt;setup-network-environment&lt;/code&gt;、&lt;code&gt;kubelet&lt;/code&gt;、&lt;code&gt;kube-proxy&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#you may use these command to start/enable your service:
sudo systemctl daemon-reload
sudo systemctl start &amp;lt;service-name&amp;gt;  #start the service
sudo systemctl enable &amp;lt;service-name&amp;gt;  #Ensure service can boot from the start
sudo systemctl status &amp;lt;service-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;check&#34;&gt;Check&lt;/h1&gt;

&lt;p&gt;Check your cluster heatlh : &lt;a href=&#34;http://10.0.0.1:8080/static/app/#/dashboard/&#34;&gt;http://10.0.0.1:8080/static/app/#/dashboard/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Check each server :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh core@10.0.0.1
journalctl -f
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;enjoy&#34;&gt;Enjoy&lt;/h1&gt;

&lt;p&gt;You may download the kubernetes client tool:&lt;code&gt;kubectl&lt;/code&gt;.Use it manage your cluster.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;get all minion node info.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;get all Pods.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;kubectl get pods
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;get all Replication Controllers.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;kubectl get rc
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;get all Replication Services.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;kubectl get svc
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/xavierbaude/VMware-coreos-multi-nodes-Kubernetes&#34;&gt;VMware-coreos-multi-nodes-Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://segmentfault.com/a/1190000002886795&#34;&gt;kubernetes 0.18.1 安装 &amp;amp; 部署 &amp;amp; 初试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://severalnines.com/blog/installing-kubernetes-cluster-minions-centos7-manage-pods-services&#34;&gt;Installing Kubernetes Cluster with 3 minions on CentOS 7 to manage pods and services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dockerpool.com/article/1422538730&#34;&gt;如何在 CoreOS 集群上搭建 Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://qiankunli.github.io/2015/01/29/Kubernetes_installation.html&#34;&gt;在CoreOS集群上搭建Kubernetes&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://dockone.io/article/604&#34;&gt;CoreOS集成Kubernetes核心组件Kubelet&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;appendix&#34;&gt;Appendix&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://gist.github.com/anonymous/553e448c0f8ce9a23120&#34;&gt;source&lt;/a&gt; of &lt;code&gt;master.yaml&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://gist.github.com/anonymous/ce88bdc1f6368c0b1589&#34;&gt;source&lt;/a&gt; of &lt;code&gt;node.yaml&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker集群系列之－ESXi5.5上搭建CoreOS集群-01</title>
      <link>http://wixb50.gitcafe.io/2015/12/15/docker%E9%9B%86%E7%BE%A4%E7%B3%BB%E5%88%97%E4%B9%8Besxi5.5%E4%B8%8A%E6%90%AD%E5%BB%BAcoreos%E9%9B%86%E7%BE%A4-01/</link>
      <pubDate>Tue, 15 Dec 2015 18:10:38 +0800</pubDate>
      <author>wixb50@gmail.com (Wixb)</author>
      <guid>http://wixb50.gitcafe.io/2015/12/15/docker%E9%9B%86%E7%BE%A4%E7%B3%BB%E5%88%97%E4%B9%8Besxi5.5%E4%B8%8A%E6%90%AD%E5%BB%BAcoreos%E9%9B%86%E7%BE%A4-01/</guid>
      <description>

&lt;h2 id=&#34;目录&#34;&gt;目录&lt;/h2&gt;

&lt;!-- MarkdownTOC --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#null-link&#34;&gt;前言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#前置条件&#34;&gt;前置条件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#安装coreos虚拟机&#34;&gt;安装CoreOS虚拟机&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#choosing-a-channel&#34;&gt;Choosing a Channel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deploying-with-vmware-vsphere-client-55&#34;&gt;Deploying with VMware vSphere Client 5.5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cloud-config&#34;&gt;Cloud-Config&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#需要说明的discovery&#34;&gt;需要说明的&lt;code&gt;discovery&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#logging-in&#34;&gt;Logging in&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#adding-new-machines&#34;&gt;Adding New Machines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#一些有用的coreos命令&#34;&gt;一些有用的CoreOS命令&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#参考资料&#34;&gt;参考资料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- /MarkdownTOC --&gt;

&lt;h2 id=&#34;前言-null-link&#34;&gt;&lt;a href=&#34;chrome://not-a-link&#34;&gt;前言&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;因为大多数环境都是适配于大公司的云平台，但是也是有折中办法的。CoreOS是一个基于Linux 内核的轻量级操作系统，为了计算机集群的基础设施建设而生，专注于自动化，轻松部署，安全，可靠，规模化。作为一个操作系统，CoreOS 提供了在应用容器内部署应用所需要的基础功能环境以及一系列用于服务发现和配置共享的内建工具。而ESXi专为运行虚拟机、最大限度降低配置要求和简化部署而设计。所以我觉得使用ESXi当作IaaS架构，运行CoreOS集群，这样是可行的。话不多少，开始把。&lt;/p&gt;

&lt;h2 id=&#34;前置条件&#34;&gt;前置条件&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;安装ESXi机器一台：怎么装自己应该知道把，如果因为驱动原因还需要自己定制安装ISO，见Google。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安装coreos虚拟机&#34;&gt;安装CoreOS虚拟机&lt;/h2&gt;

&lt;h3 id=&#34;choosing-a-channel&#34;&gt;Choosing a Channel&lt;/h3&gt;

&lt;p&gt;CoreOS is released into alpha, beta, and stable channels. Releases to each channel serve as a release-candidate for the next channel. For example, a bug-free alpha release is promoted bit-for-bit to the beta channel.&lt;/p&gt;

&lt;p&gt;The channel is selected based on the URLs below. Simply replace &lt;code&gt;stable&lt;/code&gt; with &lt;code&gt;alpha&lt;/code&gt; or &lt;code&gt;beta&lt;/code&gt; in the URL. Select 1 of these to download the appropriate image. Read the release notes for specific features and bug fixes in each channel.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -LO http://stable.release.core-os.net/amd64-usr/current/coreos_production_vmware_ova.ova
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;curl -LO http://beta.release.core-os.net/amd64-usr/current/coreos_production_vmware_ova.ova
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;curl -LO http://alpha.release.core-os.net/amd64-usr/current/coreos_production_vmware_ova.ova
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;deploying-with-vmware-vsphere-client-5-5&#34;&gt;Deploying with VMware vSphere Client 5.5&lt;/h3&gt;

&lt;p&gt;Use the vSphere Client to deploy the VM as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;in the menu, click “File &amp;gt; Deploy OVF Template…”&lt;/li&gt;
&lt;li&gt;in the wizard, specify the location of the OVA downloaded earlier&lt;/li&gt;
&lt;li&gt;name your VM&lt;/li&gt;
&lt;li&gt;choose “thin provision” for the disk format if you want the disk to grow dynamically&lt;/li&gt;
&lt;li&gt;choose your network settings&lt;/li&gt;
&lt;li&gt;confirm the settings then click “Finish”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;NOTE: Unselect “Power on after deployment” so you have a chance to edit VM settings before powering it up for the first time.&lt;/p&gt;

&lt;p&gt;The last step uploads the files to your ESXi datastore and registers your VM. You can now tweak the VM settings, like memory and virtual cores. These instructions were tested to deploy to an ESXi 5.1 host.&lt;/p&gt;

&lt;p&gt;Before powering it on, you will have to create a cloud-config.&lt;/p&gt;

&lt;h2 id=&#34;cloud-config&#34;&gt;Cloud-Config&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://coreos.com/os/docs/latest/cloud-config.html&#34;&gt;Cloud-Config&lt;/a&gt;是CoreOS内比较重要的概念，可以理解为一种配置CoreOS的方式：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Providing Cloud-Config with Config-Drive&lt;/strong&gt;&lt;br /&gt;
Cloud-config can be specified by via &lt;a href=&#34;https://github.com/coreos/coreos-cloudinit/blob/master/Documentation/config-drive.md&#34;&gt;config-drive&lt;/a&gt; with the filesystem label &lt;code&gt;config-2&lt;/code&gt;. This is commonly done through whatever interface allows for attaching CD-ROMs or new drives.&lt;/p&gt;

&lt;p&gt;First create a user_data file using the the &lt;a href=&#34;https://coreos.com/os/docs/latest/cloud-config.html&#34;&gt;cloud-config guide&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#cloud-config
hostname: core-01  #替换成你的命名的主机名
write_files:
    - path: /etc/systemd/network/static.network
      permissions: 0644  #文件权限,无需改
      content: |
        [Match]
        Name=ens192  #网卡名称,如果你的是别的名称,请改回来

        [Network]
        Address=192.1.1.150/24  #网络配置,同时把下面的IP改掉
        Gateway=192.1.1.1
        DNS=10.11.248.114
        DNS=8.8.4.4
coreos:
    etcd2:
        # generate a new token for each unique cluster from https://discovery.etcd.io/new?size=3
        discovery: https://discovery.etcd.io/&amp;lt;token&amp;gt;  #这里在后面详细讲
        # multi-region and multi-cloud deployments need to use 192.1.1.150
        advertise-client-urls: http://192.1.1.150:2379
        initial-advertise-peer-urls: http://192.1.1.150:2380
        # listen on both the official ports and the legacy ports
        # legacy ports can be omitted if your application doesn&#39;t depend on them
        listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
        listen-peer-urls: http://192.1.1.150:2380,http://192.1.1.150:7001
    fleet:
        public-ip: 192.1.1.150
        metadata: region=europe #metadata,可自定义
    flannel:
        etcd_prefix: /coreos.com/network2
    locksmith:
        endpoint: 192.1.1.150:4001
    update:
        reboot-strategy: etcd-lock
        group: stable
    units:
        - name: etcd2.service #注意是etcd2,第二版哟
          command: start
        - name: fleet.service
          command: start
users:
  - name: &amp;quot;core&amp;quot;  #改成你的用户名,可不是core
    groups:
      - &amp;quot;sudo&amp;quot;
      - &amp;quot;docker&amp;quot;
    ssh-authorized-keys:   
      - ssh-rsa 替换成你的公钥... 
manage_etc_hosts: localhost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cloud-Config配置信息验证地址&lt;a href=&#34;https://coreos.com/validate/&#34;&gt;https://coreos.com/validate/&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;需要说明的-discovery&#34;&gt;需要说明的&lt;code&gt;discovery&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;　　因为要搭建集群，需要用到服务发现，配置集群的服务发现有两种方式：一种是Static方式，第二种就是Discovery方式了。其中个人不推荐第一种方式，因为每加入一台主机就需要手动配置etcd节点，非常不方便。&lt;br /&gt;
　　第二种Discovery方式是使用远程的服务器辅助服务发现，只需要配置好Discovery的URl就可以自动把新加入的服务器加入集群。其中iscovery服务器可以使用官网提供的，也可以自己搭建(我还没搭建过，这里不介绍了)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl https://discovery.etcd.io/new?size=3  #控制台或者浏览器执行即可,推荐使用size=1,见下面说明
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中有一个&lt;code&gt;size&lt;/code&gt;参数，讲一下我遇到的问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有使用size参数结果老是启动不了;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;使用了&lt;code&gt;size=3&lt;/code&gt;，结果启动主节点，主节点的etcd2就一直等待从节点加入，结果等我去加入它的时候，已经超时了;&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;size=1&lt;/code&gt;，没有什么要等待了，过一会就自动启动成功了&lt;code&gt;fleetctl list-machines&lt;/code&gt;也能正常显示。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，我可能不知道网上哪些一下子启动3个节点是怎么做到的，还是有待学习。但是这里我也有自己的解决方法，就是使用&lt;code&gt;size=1&lt;/code&gt;先运行出来一个只有一台主机的集群，果然可以运行。然后使用主节点的&lt;code&gt;&amp;lt;Token&amp;gt;&lt;/code&gt;再去构建其他节点的&lt;code&gt;Cloud-config&lt;/code&gt;，然后运行，结果果然它自己就能加入到第一个节点里面。&lt;/p&gt;

&lt;p&gt;这里我可能投机取巧了点，但是能运行，也能达到效果就行，哈哈，希望不会有什么bug。&lt;/p&gt;

&lt;p&gt;Finally, to create a cloud-config ISO, use the following commands using the user_data file we just created:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#wrap up a config named user_data in a config drive image:
mkdir -p /tmp/new-drive/openstack/latest
cp user_data /tmp/new-drive/openstack/latest/user_data
mkisofs -R -V config-2 -o configdrive-01.iso /tmp/new-drive
rm -r /tmp/new-drive

#transform iso file to datastore
#scp configdrive-01.iso root@192.1.1.132:/vmfs/volumes/datastore1/ISO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the config-drive standard was originally an OpenStack feature, which is why you’ll see strings containing openstack. This filepath needs to be retained, although CoreOS supports config-drive on all platforms.&lt;/p&gt;

&lt;p&gt;Note: The $private_ipv4 and $public_ipv4 substitution variables referenced in other documents are not supported on VMware. You can replace all these variables by the (static) IP of the CoreOS server you’re setting up. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;coreos:
  etcd2:
    # generate a new token for each unique cluster from https://discovery.etcd.io/new?size=3
    discovery: https://discovery.etcd.io/&amp;lt;token&amp;gt;
    # multi-region and multi-cloud deployments need to use $public_ipv4
    advertise-client-urls: http://$public_ipv4:2379
    initial-advertise-peer-urls: http://$private_ipv4:2380
    # listen on both the official ports and the legacy ports
    # legacy ports can be omitted if your application doesn&#39;t depend on them
    listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
    listen-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;becomes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;coreos:
  etcd2:
    # generate a new token for each unique cluster from https://discovery.etcd.io/new?size=3
    discovery: https://discovery.etcd.io/&amp;lt;token&amp;gt;
    # multi-region and multi-cloud deployments need to use $public_ipv4
    advertise-client-urls: http://192.168.0.100:2379
    initial-advertise-peer-urls: http://192.168.0.100:2380
    # listen on both the official ports and the legacy ports
    # legacy ports can be omitted if your application doesn&#39;t depend on them
    listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
    listen-peer-urls: http://192.168.0.100:2380,http://192.168.0.100:7001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Attach the ISO to the VM as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;edit the settings of the CoreOS VM&lt;/li&gt;
&lt;li&gt;in the dialog, select “CD/DVD drive 1” in the device list&lt;/li&gt;
&lt;li&gt;select “connect at power on”&lt;/li&gt;
&lt;li&gt;choose “datastore ISO file” as the device type&lt;/li&gt;
&lt;li&gt;browse the datastore and select your config drive ISO&lt;/li&gt;
&lt;li&gt;confirm the changes and click “OK”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;NOTE:如果发现ip不对，可查看配置文件，Maybe重启一下也可以解决哟。&lt;/p&gt;

&lt;h2 id=&#34;logging-in&#34;&gt;Logging in&lt;/h2&gt;

&lt;p&gt;可以查看ESXi控制台CoreOS的IP，但是静态的自己已经知道了。&lt;/p&gt;

&lt;p&gt;Now you can login using your SSH key or password set in your cloud-config，可以登录就没必要折腾下步了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh core@192.1.1.150
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, if the cloud-config fails to apply you can append coreos.autologin to the kernel parameters on boot, the console won’t prompt for a password. This is handy for debugging.&lt;/p&gt;

&lt;p&gt;When GNU GRUB appears at boot, make sure CoreOS default is selected and press e, then add coreos.autologin after &lt;code&gt;$linux_append&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Before&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holysh1t.net/vgwtest/coreosstuff/grubautologin1.png&#34; alt=&#34;之前的启动界面&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;After&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holysh1t.net/vgwtest/coreosstuff/grubautologin2.png&#34; alt=&#34;之前的启动界面&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;When coreos.autologin is added, press &lt;code&gt;CTRL+X&lt;/code&gt; to boot CoreOS with these parameters. Note that the next time autologin will be disabled again as these kernel parameters aren’t persistent.&lt;/p&gt;

&lt;p&gt;You can now manually apply the cloud-config by using the following command in the console of CoreOS:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo /usr/bin/coreos-cloudinit --from-file /media/configdrive/openstack/latest/user_data
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;adding-new-machines&#34;&gt;Adding New Machines&lt;/h2&gt;

&lt;p&gt;按照前面所说的，如果需要把其他CoreOS加入集群，只需要把Discovery URL改成原来集群地址即可自动加入了，是不是很方便呀。&lt;/p&gt;

&lt;p&gt;If you forgot which discovery URL you used, you may look it up on one of the members of the cluster. Use the following grep command on one of your existing machines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grep DISCOVERY /run/systemd/system/etcd2.service.d/20-cloudinit.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will see a line the contains the original discovery URL, like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Environment=&amp;quot;ETCD_DISCOVERY=https://discovery.etcd.io/575302f03f4fb2db82e81ea2abca55e9&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Your basic CoreOS cluster is set up, and now you can move on to testing with it!&lt;/p&gt;

&lt;h2 id=&#34;一些有用的coreos命令&#34;&gt;一些有用的CoreOS命令&lt;/h2&gt;

&lt;p&gt;查看当前集群所有machines&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fleetctl list-machines
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看服务运行状态&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl -l status etcd2  #其中-l参数可选
systemctl -l status fleet
systemctl -l status docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看服务的运行日志&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;journalctl -u etcd2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://coreos.com/&#34;&gt;CoreOS官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ibm.com/developerworks/cn/cloud/library/1505_gutb_coreos/&#34;&gt;在 ESXi5 上部署 CoreOS 集群解决方案&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.tuicool.com/m/articles/zyaAbyJ&#34;&gt;平台云基石-CoreOS之集群篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://stable.release.core-os.net/&#34;&gt;Download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.holysh1t.net/vgwtest/coreosstuff/coreos-vmware-esxi-setup.html&#34;&gt;Running CoreOS on VMware ESXi 5.1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker Operation</title>
      <link>http://wixb50.gitcafe.io/2015/12/11/docker-operation/</link>
      <pubDate>Fri, 11 Dec 2015 18:38:38 +0800</pubDate>
      <author>wixb50@gmail.com (Wixb)</author>
      <guid>http://wixb50.gitcafe.io/2015/12/11/docker-operation/</guid>
      <description>

&lt;h2 id=&#34;目录&#34;&gt;目录&lt;/h2&gt;

&lt;!-- MarkdownTOC --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#normal-commander&#34;&gt;normal commander&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#docker-使用代理连接-docker-hub&#34;&gt;Docker 使用代理连接 Docker Hub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#存出或者载入镜像&#34;&gt;存出或者载入镜像&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#批量操作docker-commander&#34;&gt;批量操作docker commander.&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#stop-all-containers&#34;&gt;Stop all containers.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#remove-all-stopped-containers&#34;&gt;Remove all stopped containers.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#remove-all-untagged-images&#34;&gt;Remove all untagged images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#remove-all-images&#34;&gt;Remove all images&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- /MarkdownTOC --&gt;

&lt;h2 id=&#34;normal-commander&#34;&gt;normal commander&lt;/h2&gt;

&lt;h3 id=&#34;docker-使用代理连接-docker-hub&#34;&gt;Docker 使用代理连接 Docker Hub&lt;/h3&gt;

&lt;p&gt;如果你的宿主操作系统是 linux 那方法就很简单了，直接通过命令来启动服务即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo HTTP_PROXY=10.125.156.21:8118 docker -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果是只是临时使用可以用下面语句&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo HTTP_PROXY=10.125.156.21:8118 docker pull node
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;存出或者载入镜像&#34;&gt;存出或者载入镜像&lt;/h3&gt;

&lt;p&gt;存出镜像&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker save -o ubuntu_14.04.tar ubuntu:14.04
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;载入镜像&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker load &amp;lt; ubuntu_14.04.tar
#or
sudo docker --input ubuntu_14.04.tar
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;批量操作docker-commander&#34;&gt;批量操作docker commander.&lt;/h2&gt;

&lt;p&gt;NOTE: &lt;code&gt;sudo&lt;/code&gt;maybe.&lt;/p&gt;

&lt;h4 id=&#34;stop-all-containers&#34;&gt;Stop all containers.&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker stop $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;remove-all-stopped-containers&#34;&gt;Remove all stopped containers.&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker rm $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;remove-all-untagged-images&#34;&gt;Remove all untagged images&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images | grep &amp;quot;^&amp;lt;none&amp;gt;&amp;quot; | awk &amp;quot;{print $3}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;remove-all-images&#34;&gt;Remove all images&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images | grep \ | awk &#39;{print $3}&#39;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>docker安装与配置</title>
      <link>http://wixb50.gitcafe.io/2015/11/02/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 02 Nov 2015 21:38:38 +0800</pubDate>
      <author>wixb50@gmail.com (Wixb)</author>
      <guid>http://wixb50.gitcafe.io/2015/11/02/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</guid>
      <description>

&lt;h3 id=&#34;方法一-安装命令&#34;&gt;方法一：安装命令&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install apt-transport-https
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9
sudo bash -c &amp;quot;echo deb https://get.docker.io/ubuntu docker main &amp;gt; /etc/apt/sources.list.d/docker.list&amp;quot;
sudo apt-get update
sudo apt-get install lxc-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;方法二-安装命令-推荐&#34;&gt;方法二：安装命令(推荐)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;curl -sSL https://get.docker.com/ | sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;完&lt;/p&gt;

&lt;h3 id=&#34;docker资料收集&#34;&gt;Docker资料收集&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@gargar454/deploy-a-mesos-cluster-with-7-commands-using-docker-57951e020586#.74cyoyjp5&#34;&gt;Deploy a Mesos Cluster with 7 Commands Using Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://technologyconversations.com/2015/11/04/docker-clustering-tools-compared-kubernetes-vs-docker-swarm/&#34;&gt;Docker Clustering Tools Compared: Kubernetes vs Docker Swarm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mesosphere.com/blog/2014/11/10/docker-on-mesos-with-marathon/&#34;&gt;DOCKER CLUSTERING ON MESOS WITH MARATHON&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.tuicool.com/articles/nyyENrY&#34;&gt;Swarm、Fleet、Kubernetes和Mesos的比较&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>